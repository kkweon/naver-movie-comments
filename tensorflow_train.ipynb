{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'data' not in globals():\n",
    "    data = pickle.load(open(\"./train_val_test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val (1741613,)\n",
      "X_train (5224838,)\n",
      "y_val (1741613,)\n",
      "X_test (1741613,)\n",
      "y_test (1741613,)\n",
      "y_train (5224838,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "def space_tokenizer(string):    \n",
    "    return kkma.nouns(string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 10000\n",
    "N = 10000 #5224838 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_sample = N\n",
    "small_data = {\n",
    "    'X_train': data['X_train'][:N_sample],\n",
    "    'y_train': data['y_train'][:N_sample],\n",
    "    \n",
    "    'X_val'  : data['X_val'][:N_sample//3+1],\n",
    "    'y_val'  : data['y_val'][:N_sample//3+1],\n",
    "    \n",
    "    'X_test' : data['X_test'][:N_sample//3+1],\n",
    "    'y_test' : data['y_test'][:N_sample//3+1]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fh = CountVectorizer(tokenizer=space_tokenizer, ngram_range=(1,2))\n",
    "X_train = fh.fit_transform(small_data['X_train']).toarray()\n",
    "X_val = fh.transform(small_data['X_val']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 52508)\n",
      "(3334, 52508)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oh = OneHotEncoder()\n",
    "oh_train = oh.fit_transform(small_data['y_train'].reshape(-1, 1)).toarray()\n",
    "oh_val   = oh.transform(small_data['y_val'].reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, D])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "reg = tf.placeholder(tf.float32, shape=None)\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=(D, 1024), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.zeros([1024]), dtype=tf.float32)\n",
    "z2 = tf.matmul(x, W1) + b1\n",
    "b2 = tf.contrib.layers.batch_norm(z2)\n",
    "r2 = tf.nn.relu(b2)\n",
    "a2 = tf.nn.dropout(r2, keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=(1024, 10), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.zeros([10]), dtype=tf.float32)\n",
    "z3 = tf.matmul(a2, W2) + b2\n",
    "b3 = tf.contrib.layers.batch_norm(z3)\n",
    "a3 = tf.nn.dropout(b3, keep_prob)             \n",
    "y = tf.nn.softmax(a3) # Predict\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) # Real\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]) + 0.5*reg * tf.nn.l2_loss(W1) + 0.5*reg * tf.nn.l2_loss(W2))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'keep_prob': 0.74255695110058939, 'reg': 1.0153681480131223} with Acc: 0.5020995736122131\n",
      "{'keep_prob': 0.67490416503738726, 'reg': 1.0153681480131223} with Acc: 0.5092981457710266\n",
      "{'keep_prob': 0.74255695110058939, 'reg': 1.6204904327810024} with Acc: 0.5101979374885559\n",
      "{'keep_prob': 0.98622708263671588, 'reg': 1.6204904327810024} with Acc: 0.52219557762146\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "HOW_MANY_PRINT = 20\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "iterations_per_epoch = X_train.shape[0] // batch_size\n",
    "TOTAL_ITERATIONS = epochs * iterations_per_epoch\n",
    "PRINT_EVERY = TOTAL_ITERATIONS // HOW_MANY_PRINT\n",
    "saver = tf.train.Saver()\n",
    "#saver.restore(sess, \"NN_model_1\")\n",
    "kfolds_params = dict()\n",
    "kfolds_params = {\n",
    "    \"keep_prob\": np.random.uniform(0.5, 1, size=5),\n",
    "    \"reg\": np.random.uniform(0, 2, size=5),\n",
    "    \"best_params\": kfolds_params.get(\"best_params\", dict()),\n",
    "    \"best_acc\": kfolds_params.get('best_acc', 0),\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "for rg in kfolds_params['reg']:\n",
    "    for k_p in kfolds_params['keep_prob']:        \n",
    "        current_epoch = 1\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        for i in range(TOTAL_ITERATIONS):    \n",
    "            idx = np.random.choice(np.arange(N_sample), size=batch_size)\n",
    "            batch_x, batch_y = X_train[idx], oh_train[idx]\n",
    "\n",
    "            f_dict =  {\n",
    "                        x : batch_x,\n",
    "                        y_: batch_y,\n",
    "                        keep_prob: k_p,\n",
    "                        reg : rg\n",
    "                      }\n",
    "\n",
    "\n",
    "            if (i % PRINT_EVERY == 0 or i == TOTAL_ITERATIONS - 1) and kfolds_params['verbose']:\n",
    "                #f_dict[keep_prob] = 1.0        \n",
    "                loss = sess.run(cross_entropy, feed_dict = f_dict)\n",
    "                print(\"step {}/{} loss: {}\".format(i+1, TOTAL_ITERATIONS, loss))\n",
    "\n",
    "            if i % iterations_per_epoch == 0 and kfolds_params['verbose']:\n",
    "\n",
    "                train_acc = sess.run(accuracy, feed_dict={x: X_train, y_: oh_train, keep_prob: 1})\n",
    "                val_acc = sess.run(accuracy, feed_dict={x: X_val, y_: oh_val, keep_prob: 1})\n",
    "                print(\"[epoch {}/{}] train_acc: {:.4%} val_acc: {:.4%}\".format(current_epoch, epochs, train_acc, val_acc))\n",
    "                current_epoch += 1\n",
    "\n",
    "\n",
    "            #f_dict[keep_prob] = 0.5\n",
    "            sess.run(train_step, feed_dict = f_dict)\n",
    "\n",
    "\n",
    "        val_acc = sess.run(accuracy, feed_dict={x: X_val, y_: oh_val, keep_prob: 1})\n",
    "        if kfolds_params['verbose']:\n",
    "            print(\"\")\n",
    "            print(\"final valid acc: {:.4%}\".format(val_acc))\n",
    "        \n",
    "        if val_acc > kfolds_params['best_acc']:\n",
    "            kfolds_params['best_acc'] = val_acc\n",
    "            kfolds_params['best_params']['reg'] = rg\n",
    "            kfolds_params['best_params']['keep_prob'] = k_p\n",
    "            print(\"{} with Acc: {}\".format(kfolds_params['best_params'], kfolds_params['best_acc']))\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1/1560 loss: 1645.2509765625\n",
      "[epoch 1/10] train_acc: 9.2900% val_acc: 8.5783%\n",
      "step 79/1560 loss: 6.90858268737793\n",
      "step 157/1560 loss: 7.355433464050293\n",
      "[epoch 2/10] train_acc: 47.5600% val_acc: 42.6815%\n",
      "step 235/1560 loss: 6.942873954772949\n",
      "step 313/1560 loss: 6.266216278076172\n",
      "[epoch 3/10] train_acc: 50.5000% val_acc: 45.8608%\n",
      "step 391/1560 loss: 6.470705032348633\n",
      "step 469/1560 loss: 6.837285995483398\n",
      "[epoch 4/10] train_acc: 51.7600% val_acc: 46.0708%\n",
      "step 547/1560 loss: 5.033098220825195\n",
      "step 625/1560 loss: 5.0623955726623535\n",
      "[epoch 5/10] train_acc: 53.7500% val_acc: 46.7307%\n",
      "step 703/1560 loss: 4.340278625488281\n",
      "step 781/1560 loss: 4.201669692993164\n",
      "[epoch 6/10] train_acc: 56.1700% val_acc: 49.6101%\n",
      "step 859/1560 loss: 3.692446708679199\n",
      "step 937/1560 loss: 3.4516656398773193\n",
      "[epoch 7/10] train_acc: 56.5500% val_acc: 49.6101%\n",
      "step 1015/1560 loss: 3.197599411010742\n",
      "step 1093/1560 loss: 2.942538261413574\n",
      "[epoch 8/10] train_acc: 56.6800% val_acc: 50.2999%\n",
      "step 1171/1560 loss: 2.9243531227111816\n",
      "step 1249/1560 loss: 2.7743051052093506\n",
      "[epoch 9/10] train_acc: 57.4200% val_acc: 51.5897%\n",
      "step 1327/1560 loss: 2.8139641284942627\n",
      "step 1405/1560 loss: 2.4012527465820312\n",
      "[epoch 10/10] train_acc: 57.4700% val_acc: 52.1596%\n",
      "step 1483/1560 loss: 2.652653932571411\n",
      "step 1560/1560 loss: 2.4530322551727295\n",
      "\n",
      "final valid acc: 52.3995%\n"
     ]
    }
   ],
   "source": [
    "HOW_MANY_PRINT = 20\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "iterations_per_epoch = X_train.shape[0] // batch_size\n",
    "TOTAL_ITERATIONS = epochs * iterations_per_epoch\n",
    "PRINT_EVERY = TOTAL_ITERATIONS // HOW_MANY_PRINT\n",
    "saver = tf.train.Saver()\n",
    "current_epoch = 1\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "kfolds_params['verbose'] = True\n",
    "for i in range(TOTAL_ITERATIONS):    \n",
    "    idx = np.random.choice(np.arange(N_sample), size=batch_size)\n",
    "    batch_x, batch_y = X_train[idx], oh_train[idx]\n",
    "\n",
    "    f_dict =  {\n",
    "                x : batch_x,\n",
    "                y_: batch_y,\n",
    "                keep_prob: kfolds_params['best_params']['keep_prob'],\n",
    "                reg : kfolds_params['best_params']['reg']/0.5\n",
    "              }\n",
    "\n",
    "\n",
    "    if (i % PRINT_EVERY == 0 or i == TOTAL_ITERATIONS - 1) and kfolds_params['verbose']:\n",
    "        #f_dict[keep_prob] = 1.0        \n",
    "        loss = sess.run(cross_entropy, feed_dict = f_dict)\n",
    "        print(\"step {}/{} loss: {}\".format(i+1, TOTAL_ITERATIONS, loss))\n",
    "\n",
    "    if i % iterations_per_epoch == 0 and kfolds_params['verbose']:\n",
    "\n",
    "        train_acc = sess.run(accuracy, feed_dict={x: X_train, y_: oh_train, keep_prob: 1})\n",
    "        val_acc = sess.run(accuracy, feed_dict={x: X_val, y_: oh_val, keep_prob: 1})\n",
    "        print(\"[epoch {}/{}] train_acc: {:.4%} val_acc: {:.4%}\".format(current_epoch, epochs, train_acc, val_acc))\n",
    "        current_epoch += 1\n",
    "\n",
    "\n",
    "    #f_dict[keep_prob] = 0.5\n",
    "    sess.run(train_step, feed_dict = f_dict)\n",
    "\n",
    "\n",
    "val_acc = sess.run(accuracy, feed_dict={x: X_val, y_: oh_val, keep_prob: 1})\n",
    "if kfolds_params['verbose']:\n",
    "    print(\"\")\n",
    "    print(\"final valid acc: {:.4%}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN_model_1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, \"NN_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 10  1]\n"
     ]
    }
   ],
   "source": [
    "test_string = np.array([\n",
    "        \"꿀잼\",\n",
    "        \"이영화 별로에요\",\n",
    "        \"아오 진심 재미없네 개 쓰레기 영화 1점 주기도 아깝다 ㅡㅡ\"\n",
    "    ])\n",
    "test = fh.transform(test_string).toarray()\n",
    "pred = (sess.run(tf.argmax(y, 1)+1, feed_dict={x: test, keep_prob: 1}))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = fh.transform(small_data['X_test']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = oh.transform(small_data['y_test'].reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5233953"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(accuracy, feed_dict={x:X_test, y_: y_test, keep_prob: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow(Py3)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
